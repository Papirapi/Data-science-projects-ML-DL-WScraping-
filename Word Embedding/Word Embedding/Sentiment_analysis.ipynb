{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "english_stemmer=nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_word(word):\n",
    "    # Remove punctuation\n",
    "    word = word.strip('\\'\"?!,.():;')\n",
    "    # Convert more than 2 letter repetitions to 2 letter\n",
    "    # funnnnny --> funny\n",
    "    word = re.sub(r'(.)\\1+', r'\\1\\1', word)\n",
    "    # Remove - & '\n",
    "    word = re.sub(r'(-|\\')', '', word)\n",
    "    #Stem the word PorterStemmer()\n",
    "    stemmer = english_stemmer\n",
    "    word = stemmer.stem(word)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_word(word):\n",
    "\t# Check if word begins with an alphabet\n",
    "\treturn (re.search(r'^[a-zA-Z][a-z0-9A-Z\\._]*$', word) is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_emojis(text):\n",
    "\t# Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
    "\ttext = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' EMO_POS ', text)\n",
    "\t# Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "\ttext = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' EMO_POS ', text)\n",
    "\t# Love -- <3, :*\n",
    "\ttext = re.sub(r'(<3|:\\*)', ' EMO_POS ', text)\n",
    "\t# Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "\ttext = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', text)\n",
    "\t# Sad -- :-(, : (, :(, ):, )-:\n",
    "\ttext = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' EMO_NEG ', text)\n",
    "\t# Cry -- :,(, :'(, :\"(\n",
    "\ttext = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', text)\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(text):\n",
    "\t# Replace URLS by URL\n",
    "\ttext = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', 'URL ', text)\n",
    "\t# Replace EMAILS by EMAIL\n",
    "\ttext = re.sub(r'(\\w+)@([A-Z0-9]+)\\.([A-Z]{2,4})', 'EMAIL', text)\n",
    "\t# Replace hashtags by the hashtag\n",
    "\ttext = re.sub(r'#(\\S+)', r' \\1 ', text)\n",
    "\treturn text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(text):\n",
    "\t# Replace tab with space\n",
    "\ttext.replace('\\t',' ')\n",
    "\t# Remove new lines \n",
    "\ttext.replace('\\n',' ')\n",
    "\ttext.replace('\\r', ' ')\n",
    "\t# Replace 2+ dots with space\n",
    "\ttext = re.sub(r'\\.{2,}', ' ', text)\n",
    "\t# Strip space, \" and ' from text\n",
    "\ttext = text.strip(' \"\\'')\n",
    "\t# Replace multiple spaces with a single space\n",
    "\ttext = re.sub(r'\\s+', ' ', text)\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compelete_clean(text):\n",
    "\tif text:\n",
    "\t\t# Convert to lower case\n",
    "\t\tfinal_text = []\n",
    "\t\ttext = text.lower()\n",
    "\t\ttext =remove_links(text)\n",
    "\t\ttext =handle_emojis(text)\n",
    "\t\ttext =remove_spaces(text)\n",
    "\t\twords = text.split()\n",
    "\t\tfor word in words:\n",
    "\t\t\tif is_valid_word(word):\n",
    "\t\t\t\tfinal_text.append(preprocess_word(word))\n",
    "\t\treturn ' '.join(final_text)\n",
    "\treturn ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_reviews(x):\n",
    "\tif x > 3 :\n",
    "\t\treturn 'POSITIVE'\n",
    "\telif x < 3 :\n",
    "\t\treturn 'NEGATIVE'\n",
    "\telse:\n",
    "\t\treturn 'NEUTRE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Amazon_Unlocked_Mobile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \n",
       "0       5  I feel so LUCKY to have found this used (phone...           1.0  \n",
       "1       4  nice phone, nice up grade from my pantach revu...           0.0  \n",
       "2       5                                       Very pleased           0.0  \n",
       "3       4  It works good but it goes slow sometimes but i...           0.0  \n",
       "4       4  Great phone to replace my lost phone. The only...           0.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment\"] = df[\"Rating\"].apply(convert_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Reviews\"] = df[\"Reviews\"].astype(str).apply(compelete_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df[['sentiment','Reviews']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sentiment                                            Reviews\n",
      "0  POSITIVE  i feel so lucki to have found this use to us n...\n",
      "1  POSITIVE  nice nice up grade from my pantach revu veri c...\n",
      "2  POSITIVE                                         veri pleas\n",
      "3  POSITIVE  it work good but it goe slow sometim but it a ...\n",
      "4  POSITIVE  great phone to replac my lost phone the onli t...\n"
     ]
    }
   ],
   "source": [
    "print(reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_csv('prep_unlocked_mobile.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('prep_unlocked_mobile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"sentiment\"] = reviews[\"sentiment\"].astype(str)\n",
    "reviews[\"Reviews\"] = reviews[\"Reviews\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 413840 entries, 0 to 413839\n",
      "Data columns (total 2 columns):\n",
      "sentiment    413840 non-null object\n",
      "Reviews      413840 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(reviews[['sentiment','Reviews']], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorization ...\")\n",
    "countVector = CountVectorizer(min_df = 1, ngram_range = (1, 4))\n",
    "X_train_counts = countVector.fit_transform(train[\"Reviews\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying tfidf to term frequency\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_counts = countVector.transform(test[\"Reviews\"])\n",
    "X_test_tfidf = tfidf_transformer.transform(X_new_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save TFIDF\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle.dump(X_train_tfidf, open(\"train_comment_features.pickle\", \"wb\"))\n",
    "pickle.dump(X_test_tfidf, open(\"test_comment_features.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"sentiment\"]\n",
    "y_test = test[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression learning method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datavora/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/datavora/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the accuracy, recall and f1-score for Logistic Regression\n",
    "print(metrics.classification_report(y_test, prediction['Logistic'], target_names = [\"NEGATIVE\", \"POSITIVE\",\"NEUTRE\"]))\n",
    "print(accuracy_score(y_test, prediction['Logistic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, 'logreg.joblib') \n",
    "logreg = joblib.load('logreg.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.0001, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB = MultinomialNB(alpha=0.0001)\n",
    "NB.fit( X_train_tfidf, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = NB.predict( X_test_tfidf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82768,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.94      0.92      0.93     19418\n",
      "    NEGATIVE       0.93      0.66      0.77      6404\n",
      "      NEUTRE       0.95      0.99      0.97     56946\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     82768\n",
      "   macro avg       0.94      0.86      0.89     82768\n",
      "weighted avg       0.95      0.95      0.94     82768\n",
      "\n",
      "0.9461023583993814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "print(classification_report(y_test, pred_1, target_names=['POSITIVE','NEGATIVE','NEUTRE']))\n",
    "print(accuracy_score(y_test, pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datavora/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:130: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='modified_huber',\n",
       "       max_iter=None, n_iter=50, n_iter_no_change=5, n_jobs=None,\n",
       "       penalty='l2', power_t=0.5, random_state=0, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, SGDRegressor\n",
    "SGDC = SGDClassifier(loss='modified_huber', n_iter=50, random_state=0, shuffle=True)\n",
    "SGDC.fit( X_train_tfidf, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2 = SGDC.predict( X_test_tfidf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.85      0.87      0.86     19418\n",
      "    NEGATIVE       0.92      0.12      0.21      6404\n",
      "      NEUTRE       0.90      0.98      0.94     56946\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     82768\n",
      "   macro avg       0.89      0.66      0.67     82768\n",
      "weighted avg       0.89      0.89      0.86     82768\n",
      "\n",
      "0.8888217668664218\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_2, target_names=['POSITIVE','NEGATIVE','NEUTRE']))\n",
    "print(accuracy_score(y_test, pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "RandomF = RandomForestClassifier()\n",
    "RandomF.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_3 = RandomForestClassifier.predict( X_test_tfidf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_3, target_names=['POSITIVE','NEGATIVE','NEUTRE']))\n",
    "print(accuracy_score(y_test, pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBo = GradientBoostingClassifier()\n",
    "GradientBo.fit( X_train_tfidf, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_4 = GradientBoostingClassifier.predict( X_test_tfidf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_4, target_names=['POSITIVE','NEGATIVE','NEUTRE']))\n",
    "print(accuracy_score(y_test, pred_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
